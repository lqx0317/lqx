# 1.Hive机制
## 1.1.Hive介绍

### （1）hive
- Hive是基于Hadoop的一个「数据仓库工具」。它可以<u>将结构化的数据文件映射为一张数据库表</u>，并提供完整的SQL查询功能，可以将SQL语句转换为MapReduce任务进行运行。
- Hive是建立在Hadoop上的数据仓库基础构架。它提供了一系列的工具用来进行数据提取、转化、加载（ETL），并且提供了存储、查询和分析Hadoop中的大规模数据的机制。
- Hive存储系统使用的是Hadoop的HDFS。
- Hive数据处理使用的是MapReduce、Tez等

## 1.2.Hive组件

## 1.3.Hive原理

## 1.4.Hive架构

# 2.Hive组件
## 2.1.元存储 MetaStore
### （1）元存储
元存储这个组件存储了Hive中表的描述信息，其中包含表、表的分区、模式、列及其类型、表数据映射关系等。通常在实际的应用中会考虑将MetaStore中的数据存储到RDBMS，比如MySQL。

### （2）元数据表
在使用Hive进行开发时，往往需要获得一个已存在Hive表的建表语句（DDL），然而Hive本身并没有提供这样一个工具。要想还原建表DDL就必须从元数据入手。

Hive的元数据并不存放在HDFS上，而是存放在传统的RDBMS中，如MySQL等。Hive元数据对应的表大概有20个，其中和表结构信息有关的有9个，其余的10多个或为空、或只有简单的几条记录。

hive元数据表

表名|说明
-|-
✔️ TBLS|所有hive表的基本信息
TABLE_PARAM|表级属性，如是否外部表、表注释等
✔️ COLUMNS|Hive表字段信息，如字段注释、字段名、字段类型、字段序号等
✔️ SDS|所有hive表、表分区所对应的HDFS数据目录和数据格式
SERDE_PARAM|序列化反序列化信息，如行分隔符、列分隔符、NULL的表示字符等
✔️ PARTITIONS|hive表分区信息
PARTITION_KEYS|hive分区表分区键
PARTITION_KEY_VALS|hive表分区名（键值）
✔️ NUCLEUS_TABLES|保存了元数据表和hive中class类的对应关系。如类org.xxx.Mtable和表TBLS，说明MTable类对应了元数据的TBLS表。当创建一个新表时，hive通过MTable的DAO模式向源数据表TBLS插入一条数据用来描述刚刚创建的hive表
SEQUENCE_TABLE|存储在元数据表中的各种hive对象的id

### （3）Hive表创建过程
- 1.解析用户提交的Hive语句（create...），对其进行解析，分解为表、字段、分区等Hive对象。
- 2.根据解析到的信息构建对应的表、字段、分区等对象，从SEQUENCE_TABLE中获取构建对象的最新ID，与构建对象信息（名称、类型等）一同通过DAO方法写入到元数据表中

# 2.hive调优
## 2.1 前述概念
### （1）小文件
Map读取小文件：如果一个作业读取的文件多数为小文件，那么作业需要耗费额外的工作去读取小文件，如果没有配置合并读取小文件，那么意味着每读取一个文件都需要启动一个Java进程。


## 2.1 定位性能瓶颈
### ➤➤➤ Map任务读取小文件和大文件 ➤➤➤
### （1）磁盘物理块 block
物理磁盘中有块的概念，磁盘的物理block是磁盘操作最小的单元，读写操作均以block为最小单元，一般为512 Byte。

### （2）HDFS块 block
- HDFS将所有的文件全部抽象成为block块来尽心存储，不管文件大小，全部都是以block块的统一大小和形式进行存储。Hadoop2.0中文件的block块大小默认是128M。
- 比Block小的文件不会占用整个Block，只会占据实际大小。例如，如果一个文件大小为1M，则在HDFS中只会占用1M的空间，而不是128M。
- Block设置过大，在MapReduce任务中，Map或者Reduce任务的个数如果小于集群机器数量，会使得作业运行效率很低。
- 文件的所有数据块大小都是一样的，除了最后一个，它可能小于块大小或者刚好等于块大小。文件会被分割成若干个128M的小数据块，再写入HDFS。
- MapReduce的Map任务中通常一次只处理一个块中数据（切片大小默认等于block大小）

###### 例子
当我们往HDFS上上传一个362.4M的文件的时候，那么这个文件会被分成3个数据块，分别是第一个block Size:134217728（134217728 B/1024/1024=128M）、第二个block Size:134217728（128M）、第三个block Size:111564620(106.396M)。一共是128M+128M+106.396M=362.396M。

### （3）小文件
- 在将数据文件上传到HDFS，如果一个表有许多小文件组成，每个小文件小于128M，那么就会造成HDFS上有很多小于128M的小文件？？？
- 一般来说小于等于30M的文件，都叫小文件。
- 为什么会有小文件？批处理时造成过多的小文件？数据源有大量小文件，未做处理就直接拷贝到Hadoop集群；MR运算时Reduce输出没有做很好的设置
- 小文件带来的问题？在处理数据时，读取数据会有进程开启和销毁的过程，小文件过多会导致大量的网络磁盘IO的消耗；在MapReduce过程中，会开启大量的MR任务，也就是说会造成大量的shuffle过程。也会造成大量任务处于等待资源的状态。